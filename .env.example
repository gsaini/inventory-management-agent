# =============================================================================
# LLM Provider Configuration
# =============================================================================
# Supported providers: openai, ollama, openai_compatible, huggingface
LLM_PROVIDER=ollama

# -----------------------------------------------------------------------------
# Option 1: Ollama (Recommended for Local Development)
# -----------------------------------------------------------------------------
# Install: https://ollama.ai
# Pull models: ollama pull llama4:scout
# Start server: ollama serve (runs on http://localhost:11434)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama4:scout
OLLAMA_MODEL_MINI=llama4:scout

# -----------------------------------------------------------------------------
# Option 2: OpenAI-Compatible APIs (vLLM, LM Studio, LocalAI, etc.)
# -----------------------------------------------------------------------------
# vLLM:    python -m vllm.entrypoints.openai.api_server --model meta-llama/Llama-3.1-8B-Instruct
# LM Studio: Start server from GUI (default: http://localhost:1234/v1)
# LocalAI: docker run -p 8080:8080 localai/localai
OPENAI_COMPATIBLE_BASE_URL=http://localhost:1234/v1
OPENAI_COMPATIBLE_API_KEY=not-needed
OPENAI_COMPATIBLE_MODEL=local-model

# -----------------------------------------------------------------------------
# Option 3: OpenAI (Cloud)
# -----------------------------------------------------------------------------
OPENAI_API_KEY=your-openai-api-key
OPENAI_MODEL=gpt-4o
OPENAI_MODEL_MINI=gpt-4o-mini

# -----------------------------------------------------------------------------
# Option 4: HuggingFace (Cloud Inference API)
# -----------------------------------------------------------------------------
HUGGINGFACE_API_KEY=your-huggingface-api-key
HUGGINGFACE_MODEL=meta-llama/Llama-4-Scout-17B-16E-Instruct

# =============================================================================
# Database Configuration
# =============================================================================
DATABASE_URL=postgresql+asyncpg://postgres:postgres@localhost:5432/inventory_db
DATABASE_SYNC_URL=postgresql://postgres:postgres@localhost:5432/inventory_db

# Redis Configuration
REDIS_URL=redis://localhost:6379/0

# MQTT/IoT Configuration
MQTT_BROKER_HOST=localhost
MQTT_BROKER_PORT=1883
MQTT_USERNAME=
MQTT_PASSWORD=
MQTT_TOPIC_PREFIX=warehouse/sensors

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
API_DEBUG=true

# Warehouse Configuration
WAREHOUSE_ID=WH001
WAREHOUSE_NAME=Main Distribution Center

# Alert Thresholds
TEMP_MIN_CELSIUS=2.0
TEMP_MAX_CELSIUS=8.0
HUMIDITY_MIN_PERCENT=30.0
HUMIDITY_MAX_PERCENT=60.0

# Replenishment Settings
DEFAULT_LEAD_TIME_DAYS=7
SAFETY_STOCK_DAYS=3
REORDER_CHECK_INTERVAL_HOURS=1
